import streamlit as st
import pandas as pd
import plotly.express as px

# Title and Introduction
st.title("Malware Prediction Project")

st.header("Background and Introduction")
st.write("""
The traditional malware detection methods, such as signature-based and heuristic-based approaches heavily depend on expert knowledge which makes them time-consuming and less effective against evolving malware. 
AI techniques have addressed these limitations by enabling automatic feature extraction. Nataraj et al. [1] introduced malware detection by converting bytecode into grayscale images for classification with KNN. 
Recent models like CNNs and LSTMs further improved the accuracy, Le et al.’s [2] model achieved 98.2% on Microsoft's MMCC dataset. Chai et al.’s [3] proposed an LGMal framework which combines CNN and GCN and achieved an accuracy of 87.76%, while Xin et al. [4] focused on local code fragments, attaining 97.34% accuracy. 
In this project, we will use ML methods to build a robust malware prediction model using the Microsoft Malware Prediction dataset from Kaggle, which will focus on identifying infections based on Windows machine attributes.
""")

# Dataset Description
st.header("Dataset Description")
st.write("""
The Microsoft Malware Prediction dataset contains telemetry data from Windows machines, with 82 features like OS version, antivirus state, and hardware specs. Each row represents a machine, uniquely identified by "MachineIdentifier". "HasDetections" is the ground truth and indicates that Malware was detected on the machine.
""")
st.markdown("[Dataset Link](https://www.kaggle.com/c/microsoft-malware-prediction/data)")

# Problem Definition
st.header("Problem Definition")
st.write("""
The rise of malware greatly affects data security and system integrity, harming both people and enterprises. Existing cybersecurity methods fail to keep up with changing malware, resulting in inadequate protection. 
In this project we aim to construct a robust malware prediction model using machine learning methods to identify whether a Windows PC will be infected by malware depending on different attributes of that machine.
""")

# Motivation
st.header("Motivation")
st.write("""
Our motivation arises from the pressing necessity to improve security in an age of digital threats. By detecting malware attacks before they happen, we aim to help organizations and individuals implement preventive measures, protecting sensitive data and maintaining stability.
""")

# Methods
st.header("Methods")
st.write("""
For the data set, we identified columns into three categories, mainly numerical, binary, and categorical types. We are planning to employ the following data preprocessing techniques:
1. **Imputation**: For handling the missing values, we plan to use statistical analysis like mean median to impute the numerical columns and mode for the categorical columns using SimpleImputer from scikit-learn.
2. **Feature Engineering**: Dataset contains categorical features like hardware and product versions. We plan to use Label Encoding and One Hot encoding.
3. **Dimensionality Reduction**: Principal Component Analysis (PCA) with PCA from scikit-learn will be applied to simplify the high-dimensional dataset with 82 columns.
""")

# Supervised Learning Models
st.header("Supervised Learning Models")
st.subheader("1. Logistic Regression")
st.write("""
- A simple interpretable model, effective for quick benchmarking and binary classification tasks like malware detection.
- Library/Function: `LogisticRegression` from scikit-learn.
""")
st.subheader("2. Random Forest")
st.write("""
- Combines multiple decision trees, avoiding overfitting and handling complex, non-linear relationships.
- Library/Function: `RandomForestClassifier` from scikit-learn.
""")
st.subheader("3. XGBoost")
st.write("""
- Efficient for large datasets and performs well by building trees iteratively to correct errors.
- Library/Function: `XGBClassifier` from xgboost.
""")
st.subheader("4. LightGBM")
st.write("""
- Optimized for speed and memory usage, with a leaf-wise tree growth strategy that offers better performance.
- Library/Function: `LGBMClassifier` from lightgbm.
""")

# Unsupervised Learning Model
st.header("Unsupervised Learning Model")
st.subheader("1. K-Means Clustering")
st.write("""
- Groups machines with similar configurations to identify clusters prone to malware infections.
- Library/Function: `KMeans` from scikit-learn.
""")

# Results and Discussion
st.header("Potential Results and Discussion")
st.write("""
We plan to evaluate the model’s performance using metrics like AUC-PR, AUC-ROC, and F1 score to get a balanced view of its accuracy and precision. We’ll also use visual tools like a confusion matrix and precision-recall curve, as well as feature importance plots (SHAP or LIME) to show feature contributions. Model calibration plots will check prediction reliability. Our goal is a robust AUC-PR score while ensuring performance consistency across different types of malware.
""")

# References
st.header("References")
st.write("""
[1] S. a. J. Choi, “Malware detection using malware image and deep learning”.
""")
st.write("""
[2] R. Z. X. &. K. R. Khan, “Analysis of ResNet and GoogleNet models for malware detection”. 
""")
st.write("""
[3] B. Z. A. W. G. E. C. Kolosnjaji, “Deep Learning for Classification of Malware System Call Sequences”. 
""")
st.write("""
[4] Z. X. J. Z. G Ke, “DeepGBM: A deep learning framework distilled by GBDT for online prediction tasks”. 
""")

# Contribution Table
st.header("Contribution Table")
data = {
    'Name': ['Suchitra, Rishitha', 'Rishitha', 'Chetan, Kartheek', 'Sanjay', 'All', 'Suchitra'],
    'Proposal Contributions': ['Introduction & Background', 'Problem Definition', 'Methods', 'Potential Results & Discussion', 'Video Recording', 'GitHub Page']
}
df = pd.DataFrame(data)
st.dataframe(df)

# Gantt Chart
st.header("Gantt Chart")

# Task data for Gantt chart
gantt_data = {
    "Task": [
        "Introduction & Background", "Problem Definition", "Methods", "Potential Results & Discussion",
        "Video Recording", "GitHub Page", "Data Pre-Processing", "Model 1 - Random Forest", 
        "Model Coding - Random Forest", "Results Evaluation - Random Forest", 
        "Model 2 - Logistic Regression", "Model Coding - Logistic Regression", 
        "Results Evaluation - Logistic Regression", "Model 3 - XGBoost", 
        "Model Coding - XGBoost", "Results Evaluation - XGBoost", "Midterm Report", 
        "Model 4 - LightGBM", "Model Coding - LightGBM", "Results Evaluation - LightGBM", 
        "Model 5 - KMeans", "Model Coding - KMeans", "Results Evaluation - KMeans",
        "Evaluation", "Model Comparison", "Presentation", "Recording", "Final Report"
    ],
    "Owner": [
        "Suchitra, Rishitha", "Rishitha", "Chetan, Kartheek", "Sanjay", "All", "Suchitra", 
        "Kartheek, Rishitha", "Chetan", "Chetan", "Chetan", "Karthik, Rishitha", 
        "Karthik, Rishitha", "Karthik, Rishitha", "Sanjay, Suchitra", "Sanjay, Suchitra", 
        "Sanjay, Suchitra", "All", "Kartheek, Sanjay", "Kartheek, Sanjay", 
        "Kartheek, Sanjay", "Chetan, Suchitra, Rishitha", "Chetan, Suchitra, Rishitha", 
        "Chetan, Suchitra, Rishitha", "All", "All", "All", "All", "All"
    ],
    "Start": [
        "2024-09-23", "2024-09-23", "2024-09-25", "2024-09-27", "2024-09-30", "2024-09-30",
        "2024-10-05", "2024-10-13", "2024-10-13", "2024-10-26", "2024-10-16", "2024-10-16", 
        "2024-10-28", "2024-10-13", "2024-10-13", "2024-10-26", "2024-11-09", "2024-11-09", 
        "2024-11-22", "2024-11-22", "2024-11-22", "2024-11-22", "2024-11-25", 
        "2024-11-25", "2024-11-30", "2024-12-01", "2024-11-27"
    ],
    "Finish": [
        "2024-10-01", "2024-10-01", "2024-10-04", "2024-10-04", "2024-10-04", "2024-10-04",
        "2024-10-10", "2024-10-25", "2024-10-25", "2024-11
